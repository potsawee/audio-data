{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3236efc-6112-49e8-8872-58f0602b7978",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94d90481-b6a1-4d0a-b357-f1766bfa98e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame Width: 8 (I think it's in Bytes)\n",
      "Sampling Rate: 48.0 kHz\n",
      "Bitrate: 3072.0 kbps\n"
     ]
    }
   ],
   "source": [
    "# Load your audio file\n",
    "audio = AudioSegment.from_file(\"./audio/bal_train/--cB2ZVjpnA.flac\")\n",
    "\n",
    "# Get sampling rate\n",
    "sampling_rate = audio.frame_rate\n",
    "\n",
    "# Get bitrate\n",
    "bitrate = audio.frame_width * audio.frame_rate * 8\n",
    "\n",
    "print(f\"Frame Width: {audio.frame_width} (I think it's in Bytes)\")\n",
    "print(f\"Sampling Rate: {sampling_rate/1000} kHz\")\n",
    "print(f\"Bitrate: {bitrate/1000} kbps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af92533-9c6b-422f-bc61-493d76586c6b",
   "metadata": {},
   "source": [
    "## Resample sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d49e69c-b181-4b0a-a206-75025996eab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BufferedRandom name='test.flac'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the FLAC file\n",
    "audio = AudioSegment.from_file(\"./audio/bal_train/--cB2ZVjpnA.flac\", format=\"flac\")\n",
    "\n",
    "# Resample the audio to 16kHz\n",
    "resampled_audio = audio.set_frame_rate(16000)\n",
    "\n",
    "# Export the resampled audio\n",
    "resampled_audio.export(\"test.flac\", format=\"flac\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8dc7c5f2-486a-4b42-a7a6-5476fc31e8de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame Width: 8 (I think it's in Bytes)\n",
      "Sampling Rate: 16.0 kHz\n",
      "Bitrate: 1024.0 kbps\n"
     ]
    }
   ],
   "source": [
    "# Load your audio file\n",
    "audio = AudioSegment.from_file(\"test.flac\")\n",
    "\n",
    "# Get sampling rate\n",
    "sampling_rate = audio.frame_rate\n",
    "\n",
    "# Get bitrate\n",
    "bitrate = audio.frame_width * audio.frame_rate * 8\n",
    "\n",
    "print(f\"Frame Width: {audio.frame_width} (I think it's in Bytes)\")\n",
    "print(f\"Sampling Rate: {sampling_rate/1000} kHz\")\n",
    "print(f\"Bitrate: {bitrate/1000} kbps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7df23047-2991-423f-be84-0c15fa86769a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame Width: 8 (I think it's in Bytes)\n",
      "Sampling Rate: 16.0 kHz\n",
      "Bitrate: 1024.0 kbps\n"
     ]
    }
   ],
   "source": [
    "# Load your audio file\n",
    "audio = AudioSegment.from_file(\"flac_16kHz/-i-9C48tduw.flac\")\n",
    "\n",
    "# Get sampling rate\n",
    "sampling_rate = audio.frame_rate\n",
    "\n",
    "# Get bitrate\n",
    "bitrate = audio.frame_width * audio.frame_rate * 8\n",
    "\n",
    "print(f\"Frame Width: {audio.frame_width} (I think it's in Bytes)\")\n",
    "print(f\"Sampling Rate: {sampling_rate/1000} kHz\")\n",
    "print(f\"Bitrate: {bitrate/1000} kbps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34d27c0-bb42-4f2d-8998-dfcfffd28118",
   "metadata": {},
   "source": [
    "## LTU Open-QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "774c9b26-dca9-480d-8a89-31bdbdfc79ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e19444d-8132-459b-95d0-1bcb22dae588",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../ltu-openasqa/openasqa_10.3M_v2.json\") as f:\n",
    "    all_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be5c0fad-7743-4f0f-a63d-2e033f05a92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../ltu-openasqa/openasqa_10.3M_v2.thai.json\") as f:\n",
    "    all_data_thai = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "892614b2-5fdc-459c-b20a-c20f1160463a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10324230, 10324230)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_data), len(all_data_thai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd2b0b76-d957-45f3-901e-0db615e05afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 10324230/10324230 [00:05<00:00, 1752924.53it/s]\n"
     ]
    }
   ],
   "source": [
    "audioset_data = []\n",
    "for x in tqdm(all_data):\n",
    "    if \"audioset/dave_version\" in x['audio_id']: \n",
    "        audioset_data.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6f14348-0f62-4c6e-ac60-4b01234d5d29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4309357"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(audioset_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d245d263-dada-43c4-9883-dd485560b2f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 10324230/10324230 [00:04<00:00, 2115575.17it/s]\n"
     ]
    }
   ],
   "source": [
    "audioset_data_thai = []\n",
    "for x in tqdm(all_data_thai):\n",
    "    if \"audioset/dave_version\" in x['audio_id']: \n",
    "        audioset_data_thai.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c69d0680-b83f-42bf-8534-57fd014b6be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 4309357/4309357 [00:05<00:00, 800883.27it/s]\n"
     ]
    }
   ],
   "source": [
    "flac_names = set()\n",
    "for x in tqdm(audioset_data):\n",
    "    flac_name = x['audio_id'].split(\"/\")[-1]\n",
    "    flac_names.add(flac_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7636949b-f0a0-4f09-a08b-c88facbae49e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "523258"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(flac_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6e470ca4-1a9b-43a7-bda1-fdedcd83f335",
   "metadata": {},
   "outputs": [],
   "source": [
    "flac_names = list(flac_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6357ccbe-42ed-4a03-be81-830209730381",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ltu-audioset-ids.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(flac_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2799e67d-a762-45a2-8573-d82cb7cd7ea2",
   "metadata": {},
   "source": [
    "# Write a run script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "688b3377-cb41-4bd3-b462-6944e90b64db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write(path, start_id, end_id):\n",
    "    # [start_id, end_id)\n",
    "    text = \"\"\n",
    "    text += \"#!/bin/bash\\n\"\n",
    "    text += \"#$ -S /bin/bash\\n\\n\"\n",
    "    text += \"export HF_DATASETS_CACHE=/cache/.cache/huggingface/datasets\\n\"\n",
    "    text += \"export HF_HOME=/cache/.cache/huggingface\\n\"\n",
    "    text += \"export HF_HUB_CACHE=/cache/.cache/huggingface/hub\\n\\n\"\n",
    "    for i in range(start_id, end_id):\n",
    "        text += \"python download_filter_resample.py unbal_train{:03}\\n\".format(i)\n",
    "    # print(text)\n",
    "    with open(path, \"w\") as f:\n",
    "        f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "32c4723e-b14d-4af7-9b36-59c8563503e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "write(\"./run_download_unbal_0.sh\", 0, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1fd352e0-dcf2-463d-b850-d322df0135aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "write(\"./run_download_unbal_1.sh\", 100, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "98afeaa9-9c02-4ff3-ab2e-88b36afafcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "write(\"./run_download_unbal_2.sh\", 200, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "34f914da-cf23-44fe-b17c-081a8277277e",
   "metadata": {},
   "outputs": [],
   "source": [
    "write(\"./run_download_unbal_3.sh\", 300, 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fb854028-86cd-4eb2-8132-cbd70f51b248",
   "metadata": {},
   "outputs": [],
   "source": [
    "write(\"./run_download_unbal_4.sh\", 400, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "428921b4-12fe-468e-abcf-ea6f57031793",
   "metadata": {},
   "outputs": [],
   "source": [
    "write(\"./run_download_unbal_5.sh\", 500, 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "510ae60d-c48a-468a-ac51-cb4ad7706b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "write(\"./run_download_unbal_6.sh\", 600, 700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e89092e3-729d-49f8-af61-dc96c21db882",
   "metadata": {},
   "outputs": [],
   "source": [
    "write(\"./run_download_unbal_7.sh\", 700, 800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663f6962-5cdb-45ba-90e8-e2c490c18ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "write(\"./run_download_unbal_8.sh\", 800, 870)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33897bc-8afe-496f-8b11-bbcf923aa480",
   "metadata": {},
   "source": [
    "# Prepare training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "99bf6f3c-b13b-4058-92e0-dd26887d3a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run those cells above\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "66fddb64-85a3-4bcd-ae3b-4e1dbeca49ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10324230, 10324230)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_data), len(all_data_thai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2a94ce31-3762-40c0-9308-0c026fe6d5da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'What acoustic feature characterizes the sound of breathing in the audio clip?',\n",
       " 'input': '300 believers',\n",
       " 'audio_id': '/data/sls/audioset/dave_version/audio/-qb8GQR7IqM.flac',\n",
       " 'dataset': 'as_strong_train',\n",
       " 'task': 'open-ended question',\n",
       " 'output': 'The sound of breathing is low-frequency and rhythmic.'}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "16953de9-dddf-44e0-80b3-93cf1b99cd14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'คุณลักษณะทางเสียงใดที่ทำให้เกิดเสียงหายใจในคลิปเสียง',\n",
       " 'input': 'ผู้ศรัทธา 300 คน',\n",
       " 'output': 'เสียงหายใจเป็นเสียงความถี่ต่ำและเป็นจังหวะ',\n",
       " 'audio_id': '/data/sls/audioset/dave_version/audio/-qb8GQR7IqM.flac',\n",
       " 'dataset': 'as_strong_train',\n",
       " 'task': 'open-ended question'}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_thai[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a10a45ff-48fc-4842-93d6-636bd27469ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 10324230/10324230 [00:03<00:00, 2899804.42it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 10324230/10324230 [00:03<00:00, 2776713.21it/s]\n"
     ]
    }
   ],
   "source": [
    "audioset_data = []\n",
    "for x in tqdm(all_data):\n",
    "    if \"audioset\" in x['dataset']: \n",
    "        audioset_data.append(x)\n",
    "\n",
    "audioset_data_thai = []\n",
    "for x in tqdm(all_data_thai):\n",
    "    if \"audioset\" in x['dataset']: \n",
    "        audioset_data_thai.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2783e871-0841-43d9-a5d1-c8fe0d59b35b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1429437, 1429437)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(audioset_data), len(audioset_data_thai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5532c824-6e6a-4457-aced-05eeca9490fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'audio_id': '/data/sls/audioset/dave_version/audio/KEOHeXbwFEs.flac',\n",
       " 'input': \"I'm going to do a quick run through of my beautiful, colorful sheep.\",\n",
       " 'instruction': \"What's the implied meaning of the audio clip?\",\n",
       " 'output': \"From the recording, it can be inferred that the speaker is introducing their sheep, likely to an audience or for a personal project. The background sound of sheep bleating suggests that the speaker is in close proximity to the animals. The speech and background sound are related as the speaker seems to be showcasing their sheep to the audience or possibly documenting their work with the animals. This type of speech and background sound would likely be heard in an agricultural setting or at a livestock show. Overall, the recording seems to capture a moment of pride and enthusiasm for the speaker's sheep.\",\n",
       " 'task': 'open-ended question',\n",
       " 'dataset': 'audioset'}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audioset_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "389d444c-6e60-4d9d-a425-56aa4a3f2348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'ความหมายโดยนัยของคลิปเสียงคืออะไร?',\n",
       " 'input': 'ฉันจะวิ่งดูแกะแสนสวยของฉันอย่างรวดเร็ว',\n",
       " 'output': 'จากการบันทึก สามารถอนุมานได้ว่าผู้พูดกำลังแนะนำแกะของตน ซึ่งน่าจะเกิดขึ้นกับผู้ฟังหรือสำหรับโครงการส่วนตัว เสียงพื้นหลังของเสียงร้องของแกะบ่งบอกว่าผู้พูดอยู่ใกล้สัตว์มาก คำพูดและเสียงพื้นหลังมีความสัมพันธ์กันเนื่องจากผู้พูดดูเหมือนจะจัดแสดงแกะให้ผู้ชมเห็นหรืออาจบันทึกการทำงานร่วมกับสัตว์ต่างๆ เสียงพูดและเสียงพื้นหลังประเภทนี้มักจะได้ยินในสถานที่เกษตรกรรมหรือในการแสดงปศุสัตว์ โดยรวมแล้ว การบันทึกดังกล่าวดูเหมือนจะจับภาพช่วงเวลาแห่งความภาคภูมิใจและความกระตือรือร้นต่อแกะของผู้บรรยาย',\n",
       " 'audio_id': '/data/sls/audioset/dave_version/audio/KEOHeXbwFEs.flac',\n",
       " 'dataset': 'audioset',\n",
       " 'task': 'open-ended question'}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audioset_data_thai[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0c40b6e9-55e5-436b-b0ee-e1307a92c0e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 1429437/1429437 [00:08<00:00, 159885.54it/s]\n"
     ]
    }
   ],
   "source": [
    "en_examples = []\n",
    "count0, count1 = 0, 0\n",
    "for x in tqdm(audioset_data):\n",
    "    file_name = x['audio_id'].split(\"/\")[-1]\n",
    "    path = f\"/dataset/audio-data/audioset/flac_16kHz/{file_name}\"\n",
    "    if os.path.isfile(path) == False:\n",
    "        count0 += 1\n",
    "        continue\n",
    "    else:\n",
    "        count1 += 1\n",
    "    en_examples.append({\n",
    "        'path': path,\n",
    "        'task': \"QA\",\n",
    "        'Q': x['instruction'],\n",
    "        'text': x['output'],\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "87388671-fd32-4b0f-a97f-993d5d2b14af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26378, 1403059)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count0, count1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e30bbf38-62c3-426c-ba05-6977881a6faf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path': '/dataset/audio-data/audioset/flac_16kHz/ahvEBUwSslU.flac',\n",
       " 'task': 'QA',\n",
       " 'Q': 'Where is this scenario likely taking place?',\n",
       " 'text': 'This scenario is likely taking place at a birthday party or event.'}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_examples[20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "08e5f354-a096-45bc-b563-8a6684114562",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./audioset_train.en.json\", \"w\") as f:\n",
    "    json.dump(en_examples, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2ecc7124-871b-48fd-8822-3112221c44f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 1429437/1429437 [00:09<00:00, 155971.79it/s]\n"
     ]
    }
   ],
   "source": [
    "th_examples = []\n",
    "count0, count1 = 0, 0\n",
    "for x in tqdm(audioset_data_thai):\n",
    "    file_name = x['audio_id'].split(\"/\")[-1]\n",
    "    path = f\"/dataset/audio-data/audioset/flac_16kHz/{file_name}\"\n",
    "    if os.path.isfile(path) == False:\n",
    "        count0 += 1\n",
    "        continue\n",
    "    else:\n",
    "        count1 += 1\n",
    "    th_examples.append({\n",
    "        'path': path,\n",
    "        'task': \"QA\",\n",
    "        'Q': x['instruction'],\n",
    "        'text': x['output'],\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "145461d5-37f9-42d4-b23e-cce947708ce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26378, 1403059)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count0, count1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c2beb731-30ee-4d3f-83ff-7ea843213446",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'path': '/dataset/audio-data/audioset/flac_16kHz/KEOHeXbwFEs.flac',\n",
       "  'task': 'QA',\n",
       "  'Q': 'ความหมายโดยนัยของคลิปเสียงคืออะไร?',\n",
       "  'text': 'จากการบันทึก สามารถอนุมานได้ว่าผู้พูดกำลังแนะนำแกะของตน ซึ่งน่าจะเกิดขึ้นกับผู้ฟังหรือสำหรับโครงการส่วนตัว เสียงพื้นหลังของเสียงร้องของแกะบ่งบอกว่าผู้พูดอยู่ใกล้สัตว์มาก คำพูดและเสียงพื้นหลังมีความสัมพันธ์กันเนื่องจากผู้พูดดูเหมือนจะจัดแสดงแกะให้ผู้ชมเห็นหรืออาจบันทึกการทำงานร่วมกับสัตว์ต่างๆ เสียงพูดและเสียงพื้นหลังประเภทนี้มักจะได้ยินในสถานที่เกษตรกรรมหรือในการแสดงปศุสัตว์ โดยรวมแล้ว การบันทึกดังกล่าวดูเหมือนจะจับภาพช่วงเวลาแห่งความภาคภูมิใจและความกระตือรือร้นต่อแกะของผู้บรรยาย'},\n",
       " {'path': '/dataset/audio-data/audioset/flac_16kHz/UExUU9LEBmQ.flac',\n",
       "  'task': 'QA',\n",
       "  'Q': 'การรวมเสียงของเครื่องดนตรีควบคู่ไปกับเนื้อหาคำพูดมีความสำคัญอย่างไร และสิ่งนี้จะส่งผลต่อการรับรู้ของผู้ฟังอย่างไร',\n",
       "  'text': 'การใช้เครื่องดนตรีทำให้เกิดการตอบสนองทางอารมณ์ในผู้ฟัง ทำให้คำพูดมีผลกระทบและน่าจดจำมากขึ้น'},\n",
       " {'path': '/dataset/audio-data/audioset/flac_16kHz/_MuDqhGdGkk.flac',\n",
       "  'task': 'QA',\n",
       "  'Q': 'จุดประสงค์ของการใช้แมนโดลินเป็นแบ็คกราวด์คืออะไร?',\n",
       "  'text': 'แมนโดลินสร้างบรรยากาศที่สงบและผ่อนคลาย'},\n",
       " {'path': '/dataset/audio-data/audioset/flac_16kHz/E_MfXhLJHVU.flac',\n",
       "  'task': 'QA',\n",
       "  'Q': 'กิจกรรมทำอาหารประเภทใดที่อาจรวมถึงการผสมผสานระหว่างเสียงของเหลวและคำแนะนำในการเติมนม',\n",
       "  'text': 'การเตรียมสูตรอาหารที่ต้องใช้นมเป็นส่วนผสม เช่น อบเค้กหรือทำมิลค์เชค'},\n",
       " {'path': '/dataset/audio-data/audioset/flac_16kHz/nYDw4pb3Ht4.flac',\n",
       "  'task': 'QA',\n",
       "  'Q': 'เหตุใดเสียงพื้นหลังของเครื่องพิมพ์จึงดำเนินต่อไปในขณะที่คำพูดเกิดขึ้น',\n",
       "  'text': 'เครื่องพิมพ์อาจทำงานในขณะที่ผู้พูดกำลังพูด ซึ่งบ่งบอกถึงสภาพแวดล้อมที่มีงานยุ่ง'},\n",
       " {'path': '/dataset/audio-data/audioset/flac_16kHz/aJ7a35al4y4.flac',\n",
       "  'task': 'QA',\n",
       "  'Q': 'ผู้พูดอาจทำอะไรอีกบ้างนอกเหนือจากการให้อาหารสัตว์?',\n",
       "  'text': 'ข้อมูลที่ให้มาไม่ได้บ่งชี้ถึงการกระทำอื่นใดที่ผู้พูดอาจดำเนินการอยู่'},\n",
       " {'path': '/dataset/audio-data/audioset/flac_16kHz/a4pjwNS7TdM.flac',\n",
       "  'task': 'QA',\n",
       "  'Q': 'ผู้บรรยายเน้นความสำคัญของคาเปอเรย่าอย่างไร',\n",
       "  'text': 'โดยระบุว่าคาเปอเร่ไม่ใช่เรื่องตลกหรือภาพมายา'},\n",
       " {'path': '/dataset/audio-data/audioset/flac_16kHz/6SiwvrnVp-Y.flac',\n",
       "  'task': 'QA',\n",
       "  'Q': 'เนื้อหาคำพูดในการบันทึกคืออะไร?',\n",
       "  'text': 'และอย่าปล่อยคุณไปอีกเลย ด้วยอิสรภาพของคุณ เพราะฉันมีอิสระมากกว่าที่เคยมี'},\n",
       " {'path': '/dataset/audio-data/audioset/flac_16kHz/BUtL1X0l_xg.flac',\n",
       "  'task': 'QA',\n",
       "  'Q': 'ผู้พูดเป็นนักสเก็ตบอร์ดมือใหม่หรือมีประสบการณ์หรือไม่?',\n",
       "  'text': 'ไม่ชัดเจน ไม่มีกล่าวถึงในบันทึก'},\n",
       " {'path': '/dataset/audio-data/audioset/flac_16kHz/hhKEMNMu_5U.flac',\n",
       "  'task': 'QA',\n",
       "  'Q': 'สถานการณ์ใดที่เนื้อหาคำพูดและเสียงพื้นหลังดังกล่าวน่าจะปรากฏร่วมกัน',\n",
       "  'text': 'ในการประชุมเชิงพาณิชย์หรือการนำเสนอข้อมูลเกี่ยวกับหัวข้อที่เกี่ยวข้องกับสุขภาพ'}]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th_examples[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e5cac00f-4733-4430-9611-e64f488e158b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./audioset_train.th.json\", \"w\") as f:\n",
    "    json.dump(th_examples, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ac827a-e1bb-45b4-9e1b-056428fd047a",
   "metadata": {},
   "source": [
    "# AS-Strong & AudioSet (Audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6b025668-1c47-4ada-8e1d-e3b3f58c5b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 10324230/10324230 [00:06<00:00, 1711263.95it/s]\n"
     ]
    }
   ],
   "source": [
    "task_count = {}\n",
    "for x in tqdm(all_data):\n",
    "    if 'audioset' in x['audio_id']:\n",
    "        if 'audiocaps' in x['dataset'] or 'as_strong' in x['dataset'] or 'audioset' == x['dataset']:\n",
    "            continue\n",
    "        t = (x['dataset'], x['task'])\n",
    "        if t not in task_count:\n",
    "            task_count[t] = 1\n",
    "        else:\n",
    "            task_count[t] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4aed7b1e-9773-4e6c-90ac-da2e6d4e00a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('as_20k', 'open-ended question'): 183590,\n",
       " ('as_2m', 'cla_label_des'): 500139,\n",
       " ('as_20k', 'cla_label'): 18691,\n",
       " ('as_20k', 'cla_label_des'): 18691}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7b8cb722-18e9-44af-aed6-b620640ba07f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "721111"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(v for v in task_count.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7a9cd286-64ec-4931-8de6-a2c2d5408182",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 10324230/10324230 [00:12<00:00, 854946.52it/s]\n"
     ]
    }
   ],
   "source": [
    "as_strong_data = []\n",
    "count = 0\n",
    "for x in tqdm(all_data):\n",
    "    if 'as_strong' not in x['dataset']:\n",
    "        continue\n",
    "    file_name = x['audio_id'].split(\"/\")[-1]\n",
    "    path = f\"/dataset/audio-data/audioset/flac_16kHz/{file_name}\"\n",
    "    if os.path.isfile(path) == False:\n",
    "        count += 1\n",
    "        continue\n",
    "    as_strong_data.append({\n",
    "        'path': path, \n",
    "        'task': \"QA\",\n",
    "        'Q': x['instruction'],\n",
    "        'text': x['output'],\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "607bcdd0-d07c-473d-a2fc-3f02921bcd3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1555455, 28682)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(as_strong_data), count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e85c6fcc-97f8-4b1f-8b57-3acce6ef02c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./as_strong_train.en.json\", \"w\") as f:\n",
    "    json.dump(as_strong_data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7885d350-8b1f-4319-ae49-84180af5cd0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 10324230/10324230 [00:05<00:00, 2031249.80it/s]\n"
     ]
    }
   ],
   "source": [
    "as_20k_data = []\n",
    "count = 0\n",
    "for x in tqdm(all_data):\n",
    "    if x['dataset'] == \"as_20k\" and x['task'] == \"open-ended question\":    \n",
    "        file_name = x['audio_id'].split(\"/\")[-1]\n",
    "        path = f\"/dataset/audio-data/audioset/flac_16kHz/{file_name}\"\n",
    "        if os.path.isfile(path) == False:\n",
    "            count += 1\n",
    "            continue\n",
    "        as_20k_data.append({\n",
    "            'path': path, \n",
    "            'task': \"QA\",\n",
    "            'Q': x['instruction'],\n",
    "            'text': x['output'],\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8aa722bb-901a-494a-be47-78481f610c76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180085, 3505)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(as_20k_data), count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c2cbfe57-92ff-43af-828a-47074d183d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./as_20k_train.en.json\", \"w\") as f:\n",
    "    json.dump(as_20k_data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "235e8843-eb51-499e-abe3-2c137557356b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 10324230/10324230 [00:04<00:00, 2101246.73it/s]\n"
     ]
    }
   ],
   "source": [
    "as_20k_data_thai = []\n",
    "count = 0\n",
    "for x in tqdm(all_data_thai):\n",
    "    if x['dataset'] == \"as_20k\" and x['task'] == \"open-ended question\":    \n",
    "        file_name = x['audio_id'].split(\"/\")[-1]\n",
    "        path = f\"/dataset/audio-data/audioset/flac_16kHz/{file_name}\"\n",
    "        if os.path.isfile(path) == False:\n",
    "            count += 1\n",
    "            continue\n",
    "        as_20k_data_thai.append({\n",
    "            'path': path, \n",
    "            'task': \"QA\",\n",
    "            'Q': x['instruction'],\n",
    "            'text': x['output'],\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3f3889af-7ea6-4b1a-88b7-efbb652d1439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180085, 3505)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(as_20k_data_thai), count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ea2baba9-8853-416f-99c4-f52503c82045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path': '/dataset/audio-data/audioset/flac_16kHz/UhXKXjckLyY.flac',\n",
       " 'task': 'QA',\n",
       " 'Q': 'คลิปเสียงนี้สื่อถึงอารมณ์หรือบรรยากาศใด',\n",
       " 'text': 'คลิปเสียงสื่อถึงอารมณ์หรือบรรยากาศที่น่าเศร้าหรือน่าสะเทือนใจเนื่องจากมีเสียงครวญครางและร้องไห้ของมนุษย์'}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "as_20k_data_thai[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2a76fba4-37eb-4f2c-bacd-5e992011a70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./as_20k_train.th.json\", \"w\") as f:\n",
    "    json.dump(as_20k_data_thai, f, indent=4, ensure_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
